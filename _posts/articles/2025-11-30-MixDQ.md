---
layout: post
title: "[ECCV 2024]MixDQ"
date: 2025-11-30
permalink: /articles/MixDQ
toc: true
---

![MixDQ](../images/MixDQ.png)
[**MixDQ Github仓库**](https://github.com/thu-nics/MixDQ)

## 问题背景

这篇同样是与量化相关的文章，量化问题已经在上一篇 MPQ-DM 中有过详细讨论，这里不再细致讨论，仅说明 MixDQ 与 MPQ-DM 一致，都是在混合精度量化方向展开的工作.

## 论文创新

### 发现
模型不同层量化后对模型表现性能的影响不同，越靠前的层越容易导致模型表现性能大幅下降(表现为上下文语境改变或是图像质量下降)，MixDQ 论文中称这些层为 **高度敏感层**. 同时越多步数生成图像的模型对量化敏感度越低. 基于以上发现和文本 embeddings 的特征分布，MixDQ 提出一种 **BOS-aware** 的量化策略. 

![MixDQ-phe](../images/MixDQ-phe.png)

### 详细方法
依论文 Introduction 部分介绍，MixDQ 由三个内容组成：
- BOS-aware Text Embedding quantization
- Metric-decoupled sensitivity analysis
- integer-programming based mixed precision allocation

![MixDQ-method](../images/MixDQ-method.png)

输入文本经过 CLIP encoder 层后变为 text embedding 向量. 在 text embedding 中，MixDQ 发现第一个 token 总是有特别大的值 (823.5)，而其他 token 仅有 10-15 附近的值. 这是一个非常显著的 **outlier 异常值**现象，基于前一篇的讨论可知，这会严重影响 activation 量化的效果，让除第一个 token 以外的值都接近于 0，从而造成数据丢失. 

在 CLIP output 中，第一个 token 即是 tokenizer 中设置的 'Begin Of Sentence' token 即 `BOS_token`. 在不同提示词中 BOS token 的特征都一致，因而在量化计算时可以跳过这个 BOS token, 以保证量化计算的正确性. 

具体地，BOS-aware quantization 先**全精度计算**好 BOS token 的输出特征，然后将它拼接到其他 token **量化计算**的特征前. 这样 CLIP embedding 的量化 error 就被显著得降低，从而有效减缓模型精度下降问题. 由于这只是全精度计算一个 token，带来的空间开销与时间开销是可以接受的.

![MixDQ-BOS](../images/MixDQ-BOS.png)

